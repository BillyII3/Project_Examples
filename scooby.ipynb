{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1252bfee-039f-479e-8350-27ac2fde5e84",
   "metadata": {},
   "source": [
    "# DTSC-580: Data Manipulation\n",
    "## Assignment: Scooby-Doo\n",
    "\n",
    "### Name: Enter Name Before Submitting\n",
    "\n",
    "## Copyright & Academic Integrity Notice\n",
    "<span style=\"color:red\">This material is for enrolled students' academic use only and protected under U.S. Copyright Laws. This content must not be shared outside the confines of this course, in line with Eastern University's academic integrity policies. Unauthorized reproduction, distribution, or transmission of this material, including but not limited to posting on third-party platforms like GitHub, is strictly prohibited and may lead to disciplinary action. You may not alter or remove any copyright or other notice from copies of any content taken from BrightSpace or Eastern University’s website.</span>\n",
    " \n",
    "<span style=\"color:red\">© Copyright Notice 2025, Eastern University - All Rights Reserved.</span> \n",
    "\n",
    "## Overview\n",
    "\n",
    "In this assignment, you will test the skills that you have learned during this course to manipulate the provided data to answer questions about the TV show Scooby-Doo.  If you are not familiar with this show, more information can be found on [Scoobypedia](https://scoobydoo.fandom.com/wiki/Scoobypedia).\n",
    "\n",
    "> Scoobypedia is an encyclopedia on the hit television series Scooby-Doo which has been airing for over 50 years!\n",
    "> \n",
    "> The show follows the iconic mystery solving detectives, known as Mystery Inc., as they set out in the Mystery Machine to solve crime and unmask criminals, bent on revenge or committing criminal acts for their own personal gain.\n",
    "> \n",
    "> Titular character, Scooby, is accompanied by his best pal Shaggy as both vie for Scooby Snacks on their adventures! Velma brings her laser-focused intellect and initiative to collecting clues and solving mysteries. Fred is the team's leader who devises elaborate traps to catch the bad guys, while Daphne is bold and empathetic and keeps the Gang together.\n",
    "\n",
    "Please note that your notebook should be named `scooby` when submitting to CodeGrade for the automatic grading to work properly.\n",
    "\n",
    "## About Dataset\n",
    "\n",
    "This data comes from [Kaggle](https://www.kaggle.com/datasets/williamschooleman/scoobydoo-complete) thanks to manual data aggregation by Kaggle user plummye. We have included a PDF from the dataset's author that provides detailed information on how the data was collected, additional details about the features, and how the data was analyzed to identify features potentially important to the IMDB score.\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "### scoobydoo_episodes\n",
    "| variable | description |\n",
    "| ----------| ---------- |\n",
    "| index\t| index based on Scoobypedia |\n",
    "| series_name | Name of the series in which the episode takes place or in movies' cases the Scoobypedia's grouping classification |\n",
    "| network | Network the TV series takes place in, if it is a movie will use similar grouping as series.name variable |\n",
    "| season | Season of TV Series, if not TV Series will default to the format |\n",
    "| title | Title of Episode/Movie |\n",
    "| imdb | Score on IMDB (NULL if recently aired) |\n",
    "| engagement | Number of reviews on IMDB (NULL if very recently aired) |\n",
    "| date_aired | Dated aired in US |\n",
    "| run_time | Run time in min |\n",
    "| format | Type |\n",
    "\n",
    "### scoobydoo_monsters\n",
    "| variable | description |\n",
    "| ---------- | ---------|\n",
    "|index | index based on Scoobypedia |\n",
    "|monster_name | name of monster |\n",
    "|monster_gender | monster gender |\n",
    "|monster_type | monster type |\n",
    "|monster_subtype | monster subtype |\n",
    "|monster_species | monster_species |\n",
    "|monster_real | was monster real |\n",
    "|monster_amount | monster amount |\n",
    "|caught_fred | caught by Fred |\n",
    "|caught_daphnie | caught by Daphnie |\n",
    "|caught_velma | caught by Velma |\n",
    "|caught_shaggy | caught by Shaggy |\n",
    "|caught_scooby | caught by Scooby |\n",
    "|captured_fred | captured Fred |\n",
    "|captured_daphnie |\tcaptured Daphnie |\n",
    "|captured_velma  | captured Velma |\n",
    "|captured_shaggy | captured Shaggy |\n",
    "|captured_scooby | captured Scooby |\n",
    "|unmask_fred | unmask by fred |\n",
    "|unmask_daphnie | unmask by Daphnie |\n",
    "|unmask_velma | unmask by Velma |\n",
    "|unmask_shaggy | unmask by Shaggy |\n",
    "|unmask_scooby | unmask by Scooby |\n",
    "|snack_fred | snack offered by Fred |\n",
    "|snack_daphnie | snack offered by Daphnie |\n",
    "|snack_velma | snack offered by Velma |\n",
    "|snack_shaggy | snack offered by Shaggy |\n",
    "|snack_scooby | snack offered by Scooby |\n",
    "|unmask_other |\tunmask by other |\n",
    "|caught_other | caught by other |\n",
    "|caught_not | not caught |\n",
    "|trap_work_first | trap work first |\n",
    "|setting_terrain | setting type of terrain |\n",
    "|setting_country_state | setting country state |\n",
    "|suspects_amount | suspects amount |\n",
    "|non_suspect | non suspect |\n",
    "|arrested | arrested |\n",
    "|culprit_name |\tculprit name |\n",
    "|culprit_gender | culprit gender |\n",
    "|culprit_amount | culprit amount |\n",
    "|motive | motive |\n",
    "|if_it_wasnt_for | phrase at the end of show, ie \"if it wasnt for ...\" |\n",
    "|and_that | and that |\n",
    "|door_gag | door gag |\n",
    "|number_of_snacks | number of snacks |\n",
    "|split_up |\tsplit up |\n",
    "|another_mystery | another mystery |\n",
    "|set_a_trap | set a trap |\n",
    "|jeepers | Times \"jeepers\" said |\n",
    "|jinkies | Times \"jinkies\" said |\n",
    "|my_glasses\t| Times \"my glasses\" said |\n",
    "|just_about_wrapped_up | Times \"just about wrapped up\" said |\n",
    "|zoinks\t| Times \"zoinks\"said |\n",
    "|groovy\t| Times \"groovy\" said |\n",
    "|scooby_doo_where_are_you | Times \"scooby doo where are you\" said |\n",
    "|rooby_rooby_roo | Times \"rooby_rooby_roo\" said |\n",
    "|batman | batman in episode |\n",
    "|scooby_dum | scooby_dum in episode |\n",
    "|scrappy_doo | scrappy_doo in episode |\n",
    "|hex_girls | hex_girls in episode |\n",
    "|blue_falcon | blue_falcon in episode |\n",
    "|fred_va | Fred voice actor |\n",
    "|daphnie_va | Daphnie voice actor |\n",
    "|velma_va | Velma voice actor |\n",
    "|shaggy_va | Shaggy voice actor |\n",
    "|scooby_va | Scooby voice actor |\n",
    "\n",
    "## Note\n",
    "\n",
    "<u>Show Work</u>\n",
    "\n",
    "Remember that you must show your work.  Students submissions are spot checked manually to verify that they are not hard coding the answer from looking only in the file or in CodeGrade's expected output.  If this is seen, the student's answer will be manually marked wrong and their grade will be changed to reflect this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de84a525-7a89-4430-b7cf-a049bc3df279",
   "metadata": {},
   "source": [
    "## Initial Import & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8455619d-dbcb-48be-b0a8-b00c65bf18e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Do not change this option; This allows the CodeGrade auto grading to function correctly\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fda9a-9528-43e0-a30d-d1f0ca7a4c88",
   "metadata": {},
   "source": [
    "Start by importing your two data files. Take time to thoroughly explore the data. Investing effort in understanding the dataset upfront typically makes data manipulation tasks more efficient and manageable during a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005aae3a-53cc-4df4-a6f7-bd31437d631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Data Files ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c85356f-e25b-445d-a492-68abb99849f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explore Data ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9dff0b-bd26-4d3b-9f4b-91cbbe83219e",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e3bff3-3890-4fc5-85f3-950e28210da3",
   "metadata": {},
   "source": [
    "**Exercise1: Merging Datasets**\n",
    "\n",
    "Merge the two datasets and name the resulting DataFrame `scoobydoo_merged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79764f81-99b5-4c61-bc63-12bc83e6247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59864060-dfdd-4c72-b78b-192c27329194",
   "metadata": {},
   "source": [
    "**Code Check:** The shape of `scoobydoo_merged` should be `(608, 75)` after this initial merge. Note that the shape of the dataset will be different  at the end of the assignment due to some cleaning steps that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31bd610-5a0b-404b-be32-c153885d6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE CHECK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9437ee-a790-41dc-92aa-43d8f76e83da",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise2: Updating Column Names** \n",
    "\n",
    "Change every column name to lowercase and snake case.  This is a standard first step for some programmers as lowercase makes it easier to write and snake case makes it easier to copy multiple-word column names.\n",
    "\n",
    "For example, `Series Name` should end up being `series_name`. It's fine if you don't, but you should be able to accomplish this in a single line of code without using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c674a-34de-4363-b004-f5c2479d60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb679fa-5b3a-4f85-b4d6-2210a0a8f10c",
   "metadata": {},
   "source": [
    "**Code Check:** Check your columns to make sure your changes worked as expected and were saved to the `scoobydoo_merged` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084f94e-e198-4fbf-a26e-5b80f4977b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE CHECK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5479c8e-6cc9-4c28-a1fc-fe19bf73a3fb",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise3: Handle Duplicates**\n",
    "\n",
    "1) Identify and remove any duplicate rows saving your changes back to `scoobydoo_merged`. For this assignment, assume duplicates have the same `title` and `date_aired`.\n",
    "2) Reset the index for `scoobydoo_merged` ensuring that it goes from 0 to n-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2f588-8fff-43e1-97ed-cb5d1677e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776a1cb-5c8e-4659-9a03-69c967bf63e8",
   "metadata": {},
   "source": [
    "**Code Check:** Check the shape of `scoobydoo_merged`; it should now be `(603, 75)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f841a16-7794-4689-9f69-6eba87c86995",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE CHECK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042aed28-38dd-41cd-a7ee-da7a622e9c4b",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise4: Clean Runtime Column Part 1**\n",
    "\n",
    "To get ready for a later exercise, we need to clean the `run_time` column. Let's start by updating all `run_time` values in `scoobydoo_merged` to floats (e.g., clean values like `21 mins` to the float `21.0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4f931-dff2-408e-8384-538885553d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55e62e-781d-4c6d-a03b-1933953b9c78",
   "metadata": {},
   "source": [
    "**Code Check:** Check that the first five values of the `run_time` column match the following output:\n",
    "\n",
    "```\n",
    "0      21.0\r\n",
    "1      22.0\r\n",
    "2      21.0\r\n",
    "3      21.0\r\n",
    "4      21.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e30da-ecb8-4237-acc1-21e225887e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE CHECK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8249c5-6432-44b1-9e2a-af039f49cf66",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise5: Clean Runtime Column Part 2**\n",
    "\n",
    "The `run_time` column has missing values for each format type. Impute these missing values by replacing them with the average run time for their respective format type rounded to two decimals. For example, use the average run time for the \"TV Series\" format (rounded to 2 decimals) to fill null values for rows with that format, use the average run time for the \"TV Series (segmented)\" format (rounded to 2 decimals) to fill null values for rows with that format, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abada84-ddfe-4290-bf35-8a45c7cc47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fee17a-899c-4ff2-98f8-bf91381cc6bb",
   "metadata": {},
   "source": [
    "**Code Check:** 1) Ensure the `run_time` column has no missing values. 2) To confirm you imputed the correct mean values, the sum of the column should now be `14183.73`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efd04a-04ae-463b-8998-05b2bb542165",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE CHECK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb85de04-38f0-4f38-8899-e9b2a112698c",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise6: Summarize Runtime by Format**\n",
    "\n",
    "With the `run_time` column cleaned, analyze how the average run time differs across the various format types. Group your data to determine the average run time for each format type, rounded to two decimal places. Arrange your results in ascending order and save them as a Series named `Exercise6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c7a5ab-85d3-435f-a633-95fb344ef148",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d674a7-5ace-4574-bd86-d2c56a720aed",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise7: Clean the Network Column**\n",
    "\n",
    "Address the inconsistencies in the network column by standardizing entries for 'Cartoon Network.' Ensure all variations of the name (e.g., spelling differences) are replaced with a consistent format: 'Cartoon Network.'\"\n",
    "\n",
    "Hint: You can reuse code from a previous assignment for this step. As your data manipulation skills grow, you'll notice recurring patterns in your tasks. Building a library of reusable code will be valuable for future projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0427b5ed-649f-4607-9aeb-3bbf0ad184c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd0b7a-815d-4067-bf3d-28c00f9870c3",
   "metadata": {},
   "source": [
    "**Code Check:** Display the unique network values to verify that all variations of \"Cartoon Network\" have been combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf6c13-e971-48e9-9c82-6936e987ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE CHECK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4dc0bc-fe82-48a9-821a-63a306679418",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise8: Network with Highest IMDB Scores**\n",
    "\n",
    "With the `network` column cleaned, analyze the average IMDB score for each network. Identify the network with the highest average score by grouping the data, calculating the averages (rounded to two decimals), and organizing the results in ascending order. Save your final output as a Series named `Exercise8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650e714-43b3-4227-82b9-1969043bca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389ba42-c5a5-40cf-b4b8-c5e207625343",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise9: Who Caught the Most Monsters**\n",
    "\n",
    "Determine which characters caught the most monsters: Fred, Daphne, Velma, Shaggy, or Scooby. Use the columns related to monster captures (refer to the data dictionary for details) to calculate the total number of captures for each character. Sort the results in ascending order and save your final output as a Series named `Exercise9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d0789d-10dc-4037-9375-ef71bef3c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f48b086-efc4-4a2e-bb52-6353301dcc41",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise10: Who Was Most Succcessful At Traps**\n",
    "\n",
    "In the previous exercise, you identified who caught the most monsters. Now, refine this analysis by focusing only on episodes where the trap worked on the first try. Determine who was the most successful in catching monsters under these conditions.\n",
    "\n",
    "Sort the results in ascending order and save the result as a Series named `Exercise10`.\n",
    "\n",
    "Hint: You may find the code from the previous exercise helpful but will need to add an additional condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ae442-adbe-4c6e-8c02-92c22d9d4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1117754-1d82-40b2-98d0-f608d8d92b75",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise11: Add Year Aired Column**\n",
    "\n",
    "You want to determine when the show was at its peak based on total number of episodes per year. In order to get this information, you'll add a new column called `year_aired` that strips the year from the `date_aired` column.\n",
    "\n",
    "1) Make a copy of the `scoobydoo_merged` DataFrame and name it `scoobydoo_merged_year`. This ensures the original data remains unchanged, making CodeGrade grading easier.\n",
    "2) Add a new column, `year_aired`, to the copied DataFrame. Extract the year from the `date_aired` column and assign it to this new column. Ensure that the new column is an integer data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25516a15-f791-4b08-8de8-fc9e7daeedf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926c427-d3a1-42fd-9d24-e2a1c5829e6a",
   "metadata": {},
   "source": [
    "**Code Check:** Select the `date_aired` and `year_aired` columns from the `scoobydoo_merged_year` DataFrame. The output should match the following for the first and last five rows:\n",
    "\n",
    "```\n",
    "date_aired  year_aired\r\n",
    "0     9/13/1969        1969\r\n",
    "1     9/20/1969        1969\r\n",
    "2     9/27/1969        1969\r\n",
    "3     10/4/1969        1969\r\n",
    "4    10/11/1969        1969\r\n",
    "..          ...         ...\r\n",
    "598   10/1/2020        2020\r\n",
    "599   10/6/2020        2020\r\n",
    "600   2/23/2020        2020\r\n",
    "601   2/25/2021        2021\r\n",
    "602  11/13/2020        2020\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25bbd4-917f-473f-8742-46f7f042c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE CHECK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2361596d-3310-4cd5-ad4b-dfdc52bf6c16",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise12: Total Number of Episodes Per Year**\n",
    "\n",
    "Use the `scoobydoo_merged_year` DataFrame to create a Series showing the total number of episodes per year. Ensure the results are in **ascending** year order and save the result as a Series named `Exercise12`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb6555-4ebf-43a9-884c-eeefc46d1453",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb97f26-6ab4-4199-b3d8-b42293c3422b",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise13: Total Number of Episodes Per Year and Per Format**\n",
    "\n",
    "Using the `scoobydoo_merged_year` DataFrame, explore how the total number of episodes varies across years and formats. Organize the data to calculate the total episodes for each unique combination of year and then format. Keep the results in their original order, and assign your output to a Series named `Exercise13`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04fedac-6679-4878-972a-872d27ab2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e07fc-4462-43ac-999d-60d6ae97eb75",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise14: Who Offered the Most Snacks**\n",
    "\n",
    "According to the creator of the dataset, the `snack_fred`, `snack_daphnie`, `snack_velma`, `snack_shaggy`, and `snack_scooby` columns refers to \"when a member of the gang offers someone a Scooby Snack (usually \n",
    "given to Shaggy and Scooby). The person they offer does not have to eat it for this to count as TRUE\"\n",
    "\n",
    "Who offers the most snacks? Going back to the `scoobydoo_merged` DataFrame, create a Series that shows the total number of times a scooby snack was offered by each character. Sort the values in descending order, and save the output as a Series named `Exercise14`. You will only include the five columns mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55093715-fd95-4893-8fcb-6daf9657fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d8005-1cff-49d1-b029-e94d4e30e471",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise 15: Replacing Motive Values**\n",
    "\n",
    "The dataset creator noted that many entries in the `motive` column have very low counts, with some appearing only once, often in non-traditional series. To clean this column:\n",
    "\n",
    "1) Make a copy of the `scoobydoo_merged` DataFrame and name it `scoobydoo_motives`. Use the new DataFrame for this exercise.\n",
    "2) Identify the top five most common motives in the `motive` column.\n",
    "3) Replace any value not in the top five with `Other`.\n",
    "4) Check the value counts of the updated motive column and save the value counts as `Exercise15`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622d642-92e6-4e3f-af84-c3ffdbdce0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8137c5-8937-4e84-9d07-b4274ed0b4ad",
   "metadata": {},
   "source": [
    "**Code Check:** As a check, after replacing the appropriate values, you should have 188 `Other` entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056d67b-d7e8-4917-9440-9c57f6516deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE CHECK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ce991-ec4a-4b80-b211-6737362e5c5d",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise16: Binning IMDB Values**\n",
    "\n",
    "Let's now practice binning the IMDB values. Your task is to put these values into the following categorical bins: `unknown`,`0-4.9`,`5-5.9`,`6-6.9`,`7-7.9`,`8-8.9`,`9-9.9`,`10`. \n",
    "\n",
    "1) Make a copy of the `scoobydoo_merged` DataFrame and name it `scoobydoo_binning`. Use the new DataFrame for this exercise.\n",
    "2) The category labels should be ordered and exactly match the above in the exact order.\n",
    "3) Missing values should be replaced with the `unknown` category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75136a51-f60d-4fdf-adc9-3e54b360cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f7b160-46e8-4d51-9700-9696e6efb427",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise17: Create Terrain Dummy Values**\n",
    "\n",
    "Practice creating dummy variables for the `setting_terrain` column.\n",
    "\n",
    "1) Make a copy of the `scoobydoo_merged` DataFrame and name it `scoobydoo_terrain`. Use the new DataFrame for this exercise.\n",
    "2) Encode the `setting_terrain` column into dummy variables, ensuring to drop the first category and set the data type to integers. Use a prefix of `terrain` for the new columns (e.g., `terrain_Urban`, `terrain_Rural`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c8dfe-7f10-4378-bd0c-21e213202fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04403072-5d3e-44a9-aae7-d1c4e600ceef",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise18: Catchphrases Per Minute**\n",
    "\n",
    "For those of you that have ever watched the show, I'm sure you've heard their catchphrases often: 'jeepers', 'jinkies', 'my_glasses', 'just_about_wrapped_up', 'zoinks', 'groovy', 'scooby_doo_where_are_you', 'rooby_rooby_roo'\n",
    "\n",
    "Analyze which catchphrase is used the most per minute across all episodes. \n",
    "\n",
    "1) Make a copy of the `scoobydoo_merged` DataFrame and name it `scoobydoo_catchphrase`. Use the new DataFrame for this exercise.\n",
    "2) In this new DataFrame, calculate a per-minute value for each catchphrase by dividing the respective catchphrase column by the total minutes in the run_time column. Round the results to two decimal places and name the new columns with a `_per_minute` suffix (e.g., `jeepers_per_minute`, `jinkies_per_minute`, etc.).\n",
    "3) Once the new columns are created, select only these columns, sum their values, and sort the results in descending order. Save the final output as a Series named `Exercise18`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52638c76-f0cd-40dc-a204-43edf31cb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a4df1-d320-4943-8099-beca91611e1f",
   "metadata": {},
   "source": [
    "**Code Check:** As a check, `zoinks_per_minute` should be 66.98."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e4349-9f6a-4009-aacf-ea1f05b7952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE CHECK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d09aa-725b-45fe-98d1-50f6e8892b5c",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise19: Working with Strings**\n",
    "\n",
    "If you take a look at the `monster_name`, `monster_gender`, `monster_type`, `monster_subtype`, and the `monster_species` columns, you will notice that some columns have multiple values separated by commas when more than one monster is in the episode. Your goal is to separate these values so that each monster and its corresponding attributes are placed in their own new columns.\n",
    "\n",
    "1) Make a copy of the `scoobydoo_merged` DataFrame and name it `scoobydoo_strings`. Use the new DataFrame for this exercise.\n",
    "2) For each of the monster columns mentioned above, split the values into separate columns. Name the new columns using the pattern `<original_column_name>_part_#`, where # represents the sequence number of the monster (e.g., `monster_name_part_1`, `monster_name_part_2`, etc.). Ensure that the corresponding attributes (e.g., gender, type) follow the same pattern (e.g., `monster_gender_part_1`, `monster_gender_part_2`, etc.).\n",
    "3) Make sure that you strip any leading or trailing spaces for the values.\n",
    "    - Run the following code check to ensure the trailing space before \"Disguised\" is removed. You should see four occurrences of \"Disguised\": `scoobydoo_strings['monster_type_part_11'].value_counts()`\n",
    "\n",
    "For example, let's say that an instance of `monster_name` contained three values: `Black Knight`, `Werewolf`, `Dracula`. `Black Knight` would end up in a new column called `monster_name_part_1`. `Werewolf` would end up in a new column called `monster_name_part_2`. `Dracula` would end up in a new column called `monster_name_part_3`. Their respective monster attributes would work similar such as `monster_gender_part_1` for the `Black Knight`'s gender, `monster_gender_part_2` for the `Werewolf`'s gender, `monster_gender_part_3` for `Dracula`'s gender, etc.\n",
    "\n",
    "Hint: There are many ways to approach this problem. One approach is to use nested loops. The outer loop can iterate through the list of monster columns, and the inner loop can split the values and create the new columns with the appropriate suffixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d2fdb-5aff-4c62-8a77-32b1548d591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096a5c74-8216-4235-b892-24c248b0a944",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Exercise20: Pivot Tables**\n",
    "\n",
    "Create a pivot table to analyze the average IMDB scores, broken down by network for the rows and format for the columns. Ensure that missing values are filled with `0` in the resulting pivot table, and include both row and column totals in your pivot table. Save the result as `Exercise20`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f35c4-3131-40de-952a-abdc06362f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cabcc6-ba33-417f-8630-e6656d68f336",
   "metadata": {},
   "source": [
    "Congrats on completing the Scooby-Doo data assignment! You've unmasked data mysteries and earned your spot in the Scooby gang as a Numpy and Pandas pro. Keep solving those data mysteries! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
